# -*- coding: utf-8 -*-
"""tweets_crawler.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g2lR4wsV6vcfX8b09uf_pXiX6HreiuCI

# To extract Twitter's tweets

This script extracts all the tweets with hashtag #covid-19 related to the day before today (yesterday) and saves them into a .csv file.
We use the `tweepy` library, which can be installed with the command `pip install tweepy`.
"""

!pip install tweepy
import sys
import csv
import tweepy
import datetime

TWITTER_CONSUMER_KEY = 'vLcxeGYqPTm2De02u5Fa0c2Zs'
TWITTER_CONSUMER_SECRET = 'htu890Ysc8RCdN5eMkh25P6qDehVCbpAh0zNIKH8M55AK5RHqo'
TWITTER_ACCESS_TOKEN = '108051742-qVpGsVGEpCTf7B5xvbNs5jYHuHKaAwlpmqQQVjgq'
TWITTER_ACCESS_TOKEN_SECRET = 'goRE81O2jfuvtCGWWjspF7Fsibk3VUi2qApbJ3nZCb4l5'

"""We setup the connection to our Twitter App by using the `OAuthHandler()` class and its `access_token()` function. Then we call the Twitter API through the `API()` function."""

auth = tweepy.OAuthHandler(TWITTER_CONSUMER_KEY, TWITTER_CONSUMER_SECRET)
auth.set_access_token(TWITTER_ACCESS_TOKEN, TWITTER_ACCESS_TOKEN_SECRET)
api = tweepy.API(auth,wait_on_rate_limit=True)

"""Now we setup dates. We need to setup today and yesterday."""

today = datetime.date.today()
yesterday= today - datetime.timedelta(days=1)
today, yesterday

"""We search for tweets on Twitter by using the `Cursor()` function. 
We pass the `api.search` parameter to the cursor, as well as the query string, which is specified through the `q` parameter of the cursor.
The query string can receive many parameters, such as the following (not mandatory) ones:
* `from:` - to specify a specific Twitter user profile
* `since:` - to specify the beginning date of search
* `until:` - to specify the ending date of search
The cursor can also receive other parameters, such as the language and the `tweet_mode`. If `tweet_mode='extended'`, all the text of the tweet is returned, otherwise only the first 140 characters.
"""

tweets_list = tweepy.Cursor(api.search, q="#Covid-19 since:" + str(yesterday)+ " until:" + str(today),tweet_mode='extended', lang='it').items()

tweets_list = tweepy.Cursor(api.search, q="from: elonmusk",tweet_mode='extended', lang='en').items()

"""Optionally, we can extract tweets from a given places, by specifying in the query string one of the following keywords, followed by `:`: 
* `place` - the place name or the place ID
* `place_country` - the country code. See [here](https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2) to see the country code
* `point_radius` - the circular geographic area within which to search for
* `bounding_box` - the 4 sided geographic area, within which to search for.

For more details, you can read the full [Twitter Documentation](https://developer.twitter.com/en/docs/tutorials/filtering-tweets-by-location).

Here 
"""

place = 'India'
tweets_list = tweepy.Cursor(api.search, q="place: " + place,tweet_mode='extended', lang='en').items()

"""Now we loop across the `tweets_list`, and, for each tweet, we extract the text, the creation date, the number of retweets and the favourite count. We store every tweet into a list, called `output`."""

output = []
for tweet in tweets_list:
    text = tweet._json["full_text"]
    print(text)
    favourite_count = tweet.favorite_count
    retweet_count = tweet.retweet_count
    created_at = tweet.created_at
    
    line = {'text' : text, 'favourite_count' : favourite_count, 'retweet_count' : retweet_count, 'created_at' : created_at}
    output.append(line)

output

"""Finally, we convert the `output` list to a `pandas DataFrame` and we store results."""

output

import pandas as pd

df = pd.DataFrame(output)
df.to_csv('output.csv', mode='a', header=False)
df.to_csv('output.csv')

df.shape

df.head(10)